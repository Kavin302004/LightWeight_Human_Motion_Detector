{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9404b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(r\"D:\\GAIT\\2-06-24\\yolov3-tiny.weights\", r\"D:\\GAIT\\2-06-24\\yolov3-tiny1.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Load COCO names\n",
    "with open(r\"D:\\GAIT\\2-06-24\\coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Define the human class\n",
    "human_class_id = classes.index(\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0394154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video capture\")\n",
    "    exit()\n",
    "\n",
    "# Read the initial background frame\n",
    "ret, background = cap.read()\n",
    "\n",
    "# Check if the frame was read successfully\n",
    "if not ret:\n",
    "    print(\"Error: Could not read frame from camera\")\n",
    "    exit()\n",
    "background_gray = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "background_gray = cv2.GaussianBlur(background_gray, (21, 21), 0)\n",
    "\n",
    "def detect_motion(frame, background_gray, threshold=25):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "    diff = cv2.absdiff(background_gray, gray_frame)\n",
    "    _, thresh = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return len(contours) > 0\n",
    "\n",
    "def detect_human(frame):\n",
    "    height, width, channels = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    human_boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            if class_id == human_class_id:\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.4:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    human_boxes.append((x, y, w, h))\n",
    "    return human_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba94f45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n",
      "Human Motion Detected!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Read frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame from camera\")\n",
    "        break\n",
    "    \n",
    "    # Convert frame to grayscale for motion detection\n",
    "    background_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Check for motion\n",
    "    if detect_motion(frame, background_gray):\n",
    "        # Detect humans\n",
    "        if detect_human(frame):\n",
    "            print(\"Human Motion Detected!\")\n",
    "            human_boxes = detect_human(frame)\n",
    "        \n",
    "        # Draw rectangles around humans\n",
    "            for (x, y, w, h) in human_boxes:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, 'Human', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    # Print status in console\n",
    "    \n",
    "    \n",
    "    # Exit loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0282c2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286d34a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2f39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c82ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b83f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
